{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xov9MalKJ0KEmzbcllvjGgAn6rVpCc1P",
      "authorship_tag": "ABX9TyNX4P/Cw0w2eCrF3+/frODc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8768895c116c4c7e8758b2eccde4019c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b54836585ef74312ac524cbc663af757",
              "IPY_MODEL_70e0701c20214f07ab5586ec2ee6825f",
              "IPY_MODEL_9a1ac4ab1fc346cfb790532243fca824"
            ],
            "layout": "IPY_MODEL_f35b3aef91694a119194bc108a087a0c"
          }
        },
        "b54836585ef74312ac524cbc663af757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c2ef557a6f4b45b08e220cff583a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_f2e9ebb0065d406a84f0823450ab5585",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "70e0701c20214f07ab5586ec2ee6825f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b3771a305b645b9a766699b167c2d45",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c0f3dc0e0e647c68cc29ed9ae83d120",
            "value": 2
          }
        },
        "9a1ac4ab1fc346cfb790532243fca824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd79ac3f634249ebb24fed3f49aa36fa",
            "placeholder": "​",
            "style": "IPY_MODEL_fdf28b9417f04061b5c110752421b9c7",
            "value": " 2/2 [01:18&lt;00:00, 36.69s/it]"
          }
        },
        "f35b3aef91694a119194bc108a087a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c2ef557a6f4b45b08e220cff583a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e9ebb0065d406a84f0823450ab5585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b3771a305b645b9a766699b167c2d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0f3dc0e0e647c68cc29ed9ae83d120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd79ac3f634249ebb24fed3f49aa36fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf28b9417f04061b5c110752421b9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eedd41f2abd94799b2161181bb203ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef264ca1ff5d4175ae31a45fc3785a6c",
              "IPY_MODEL_d4f24d9b6f8b4f7bbe609f35994a427c",
              "IPY_MODEL_8964c13061b54c759dc0b00fd1dda502"
            ],
            "layout": "IPY_MODEL_a41ed7090e334035a9cf19154a2222cb"
          }
        },
        "ef264ca1ff5d4175ae31a45fc3785a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a072b0d27047dd846faca85a27f8be",
            "placeholder": "​",
            "style": "IPY_MODEL_e1fec84c6561424e8c1478ddcdfa8b2a",
            "value": "generation_config.json: 100%"
          }
        },
        "d4f24d9b6f8b4f7bbe609f35994a427c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5cdbf2ada9c43788307f50cde152d87",
            "max": 117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6c6f93cbfdd4643bbfcefe0f60bacf1",
            "value": 117
          }
        },
        "8964c13061b54c759dc0b00fd1dda502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e77d0217e2be4967b207cc8d023c0f3d",
            "placeholder": "​",
            "style": "IPY_MODEL_34c1c1a7bbdb432dbdf4c44e02b4d1dd",
            "value": " 117/117 [00:00&lt;00:00, 6.72kB/s]"
          }
        },
        "a41ed7090e334035a9cf19154a2222cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a072b0d27047dd846faca85a27f8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1fec84c6561424e8c1478ddcdfa8b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5cdbf2ada9c43788307f50cde152d87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c6f93cbfdd4643bbfcefe0f60bacf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e77d0217e2be4967b207cc8d023c0f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c1c1a7bbdb432dbdf4c44e02b4d1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowriks12/Qna-Chatbot/blob/hfmodels/RAG_huggingface_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7WrHPXoG0uH"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install pinecone-client\n",
        "# !pip install OpenAI==0.28.1\n",
        "!pip install tiktoken\n",
        "!pip install pyPDF2\n",
        "!pip install HuggingFace\n",
        "!pip install InstructorEmbedding\n",
        "!pip install sentence_transformers\n",
        "!pip -qqq install bitsandbytes accelerate\n",
        "!pip install torch\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import streamlit as st\n",
        "# from dotenv import load_dotenv\n",
        "import torch\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain import HuggingFaceHub\n",
        "# from htmlTemplates import bot_template, user_template, css"
      ],
      "metadata": {
        "id": "yCMeVs-eOg5K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "I4xbtSQ-e3S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is NOT available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0k8ostNjaj6",
        "outputId": "a5cde0fa-a519-420c-e0d0-04c5f2614edd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'key'\n",
        "print(os.environ.get('HUGGINGFACEHUB_API_TOKEN'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U5CjxLZgIsw",
        "outputId": "32154e96-9e80-4ddf-824d-1784dc6457aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pdf_text(pdf_file):\n",
        "\n",
        "    text = \"\"\n",
        "\n",
        "    # for pdf_file in pdf_files:\n",
        "    # pdf_file = \"/content/drive/MyDrive/Colab Notebooks/ChatLLMSearch/WCBasicAdminGuide.pdf\"\n",
        "    reader = PdfReader(pdf_file)\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "R7GESHICOSQg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chunk_text(text):\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len\n",
        "    )\n",
        "\n",
        "    chunks = text_splitter.split_text(text)\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "dVsNE_MOOWoh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector_store(text_chunks):\n",
        "\n",
        "\n",
        "    # For Huggingface Embeddings\n",
        "\n",
        "    # embeddings = HuggingFaceInstructEmbeddings(model_name = \"hkunlp/instructor-xl\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',model_kwargs={'device': 'cuda'})\n",
        "\n",
        "    vectorstore = FAISS.from_texts(texts = text_chunks, embedding = embeddings)\n",
        "\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "yWH6pZssOX1R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pdf_files = st.file_uploader(\"Choose your PDF Files and Press OK\", type=['pdf'], accept_multiple_files=True)\n",
        "# loader = PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/ChatLLMSearch/WCBasicAdminGuide.pdf\")\n",
        "pdf_file = \"/content/drive/MyDrive/Colab Notebooks/ChatLLMSearch/Document-Content-2.pdf\"\n",
        "raw_text = get_pdf_text(pdf_file)\n",
        "# pages = loader.load_and_split()\n",
        "# Get Text Chunks\n",
        "text_chunks = get_chunk_text(raw_text)\n",
        "vector_store = get_vector_store(text_chunks)\n",
        "\n"
      ],
      "metadata": {
        "id": "Le26ZQeHP9X1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "def get_conversation_chain(vector_store):\n",
        "\n",
        "    # HuggingFace Model\n",
        "    model = \"tiiuae/falcon-7b-instruct\"\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "    # Load model\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model,\n",
        "        trust_remote_code=True,\n",
        "        load_in_8bit=True,\n",
        "        device_map=device\n",
        "    )\n",
        "    # Set to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    generate_text = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer,\n",
        "                         trust_remote_code=True, max_new_tokens=100,\n",
        "                         repetition_penalty=1.1, model_kwargs={\"device_map\": \"auto\",\n",
        "                          \"max_length\": 1500, \"temperature\": 0.01, \"torch_dtype\":torch.bfloat16}\n",
        "    )\n",
        "    # LangChain HuggingFacePipeline set to our transformer pipeline\n",
        "    hf_pipeline = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "\n",
        "    # llm = HuggingFaceHub(repo_id=\"tiiuae/falcon-7b-instruct\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "\n",
        "    conversation_chain = RetrievalQA.from_chain_type(llm=hf_pipeline, chain_type=\"stuff\",\n",
        "                                 retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
        "                                 return_source_documents=True,\n",
        "                                 verbose=False,\n",
        "    )\n",
        "\n",
        "\n",
        "    # conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "    #     llm = hf_pipeline,\n",
        "    #     retriever = vector_store.as_retriever(),\n",
        "    #     memory = memory\n",
        "    # )\n",
        "\n",
        "    return conversation_chain"
      ],
      "metadata": {
        "id": "NtkWs5rWO2Cn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = get_conversation_chain(vector_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "8768895c116c4c7e8758b2eccde4019c",
            "b54836585ef74312ac524cbc663af757",
            "70e0701c20214f07ab5586ec2ee6825f",
            "9a1ac4ab1fc346cfb790532243fca824",
            "f35b3aef91694a119194bc108a087a0c",
            "65c2ef557a6f4b45b08e220cff583a1f",
            "f2e9ebb0065d406a84f0823450ab5585",
            "9b3771a305b645b9a766699b167c2d45",
            "1c0f3dc0e0e647c68cc29ed9ae83d120",
            "fd79ac3f634249ebb24fed3f49aa36fa",
            "fdf28b9417f04061b5c110752421b9c7",
            "eedd41f2abd94799b2161181bb203ac9",
            "ef264ca1ff5d4175ae31a45fc3785a6c",
            "d4f24d9b6f8b4f7bbe609f35994a427c",
            "8964c13061b54c759dc0b00fd1dda502",
            "a41ed7090e334035a9cf19154a2222cb",
            "f9a072b0d27047dd846faca85a27f8be",
            "e1fec84c6561424e8c1478ddcdfa8b2a",
            "f5cdbf2ada9c43788307f50cde152d87",
            "e6c6f93cbfdd4643bbfcefe0f60bacf1",
            "e77d0217e2be4967b207cc8d023c0f3d",
            "34c1c1a7bbdb432dbdf4c44e02b4d1dd"
          ]
        },
        "id": "8u0nPud47TOr",
        "outputId": "e7934661-4e6e-431d-e495-5e7cd9876be3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.tiiuae.falcon-7b-instruct.cf4b3c42ce2fdfe24f753f0f0d179202fea59c99.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8768895c116c4c7e8758b2eccde4019c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eedd41f2abd94799b2161181bb203ac9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does change notice represent?\"\n",
        "result=chain({\"query\": query})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfhG415i74Pr",
        "outputId": "1290c74a-5023-47bb-fe54-74337530f25b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What does change notice represent?', 'result': '\\nThe change notice represents a work authorization to document and release new designs, to enhance existing designs, or to correct problems.', 'source_documents': [Document(page_content='Implementation Board reviews and either approves or denies the implementation plan included \\nin the change notice.Change NoticeA change notice represents a work authorization to document \\nand release new designs, to enhance exist ing designs, or to correct problemsThe change notice \\ncan be created in reference to one or more change requests. It details the tasks that need to be \\ncompleted in order for the change to be implemented. It also enables you to assign the tasks to \\nindividual s.Change ObjectsChange objects are objects available in the change management \\nprocess. Change requests, change notices, change tasks, problem reports, variances, and change \\nreviews are change objects available out of the box.Change RequestA change request can be \\ncreated in response to one or more problem reports or without any reference to a problem report. \\nIt details the changes necessary to correct the problem or provide the enhancement so that the'), Document(page_content='The second change administrator (Change Administrator II) is responsible for creating th e \\nimplementation plan captured in the change notice. Change Administrator II is also responsible \\nfor recording the decision of the Change Implementation Board to proceed with the \\nimplementation plan.  \\n \\nThe third change administrator (Change Administrator III) acts as an auditor for all of the \\nmaterial related to a change, ensuring that all resulting documentation is clear, concise, and valid, \\nand that all process steps are properly executed.  \\n \\nChange Implementation Board (CIB)  \\n \\nA Change Implementation Board r eviews and either approves or denies the implementation plan \\nincluded in the change notice.  \\n \\nChange Notice  \\n \\nChange Notice  \\n \\nA change notice represents a work authorization to document and release new designs, to \\nenhance existing designs, or to correct problems  \\n \\nThe change notice can be created in reference to one or more change requests. It details the tasks'), Document(page_content='enhance existing designs, or to correct problems  \\n \\nThe change notice can be created in reference to one or more change requests. It details the tasks \\nthat need to be completed in order for the change to be implemented. It also enables you to \\nassign the tasks to individuals.  \\n \\nChange Objects  \\n \\nChange objects are objects available in the change management process. Change requests, \\nchange notices, change tasks, problem reports, variances, and change reviews are change objects \\navailable out of the box.  \\n \\nChange Req uest  \\n \\nChange Request  \\n \\nA change request can be created in response to one or more problem reports or without any reference to a problem report. It details the changes necessary to correct the problem or provide \\nthe enhancement so that the appropriate people can make the business decision to proceed with \\nor cancel the proposed change.  \\n \\nChange Review Board (CRB)  \\n \\nA Change Review Board reviews and either approves or denies a change request. It is typically')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the tools for collaboration that windchill provides?\"\n",
        "result=chain({\"query\": query})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvbElfoD7a0h",
        "outputId": "41580b3c-32b6-40f4-9af2-7ab2c066e524"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What are the tools for collaboration that windchill provides?', 'result': '\\nWindchill provides a variety of tools for collaboration, including:\\n\\n1. Windchill Collaboration Server: This is a web-based platform that allows users to collaborate on documents, manage workflows, and share information.\\n\\n2. Windchill Online Viewer: This is a web-based viewer that allows users to view and edit documents in real-time.\\n\\n3. Windchill Online Viewer for SAP: This is a web-based viewer that allows users to view', 'source_documents': [Document(page_content='submissions.  \\n \\nAdditional Information  \\n \\nFor a general overview, including information about quality utilities, seeWindchill Quality \\nSolutions Navigation.  \\n \\nTo installWindchill Risk and Reliability, seeInstalling the Windchill Quality Management \\nSystem.  \\n \\n \\nUsing Packages to Import and Export Data for Offline Collaboration  \\n \\nWindchillpackages provide collaboration opportunities with people that work outsid e of \\nyourWindchillinstallation. There are many variations to these collaboration scenarios, but there \\nare two main categories of collaboration: between two separate companies and between two \\ninstallations within a given company. The primary difference in t hese collaboration scenarios is the intended recipient of theWindchilldata.Windchillpackages provide different capabilities to \\nmeet the needs of these two collaboration scenarios.  \\n \\nIn many business scenarios, two companies might need to collaborate on a specific configuration'), Document(page_content='information once it has been shared to the project  \\n \\n•Recipient has full access to theWindchillinstallation and is able to access the information \\ndirectly  \\n \\nOnce the recipient has the information, they will either use the application files directly in their \\nnative application (via the offline viewer) or they will import the information into \\ntheirWindchillinstallation.  \\n \\nThe other scenario whereWindchillpackages can be used to improve collaboration is between \\ntwoWindchillinstallations within the same comp any. For example, a company might have \\ntwoWindchillinstances for security (such as an unclassified and a classified installation) or \\ngeographical considerations with the desire to replicate a common part or document library \\nbetween them. A replication pack age can be used to replicate the information in these libraries \\nfrom one system to the other.  \\n \\nRelated TopicsSending and Receiving Windchill Packages  \\n \\nRelated Topics  \\n \\nSending and Receiving Windchill Packages'), Document(page_content='resources withinWindchill, Digital Product Traceability uses Open Service Lifecycle \\nCollaboration (OSLC) standards andThingWorx Flow.  \\n \\nRefer the following sections for more inform ation.  \\n \\nSubjectDescriptionIntended AudienceUnderstanding the Integration ArchitecturePotential \\narchitecture ofWindchilland external system integration.WindchillAdministratorSystem \\nCompatibility and RequirementsPrerequisites required to get started with the \\nintegra tion.WindchillAdministratorConfiguring the Windchill Digital Product Traceability \\n(DPT) Extension in ThingWorxSteps to follow inThingWorx Flowconfigure \\ntheWindchillextension.WindchillAdministrator,ThingWorx FlowAdministratorWorking with TracesSetting up trace links and adding them toWindchilltraceable \\nobjects.WindchillAdministrator, Power user  \\n \\nSubject  \\n \\nDescription  \\n \\nIntended Audience  \\n \\nUnderstanding the Integration Architecture  \\n \\nPotential architecture ofWindchilland external system integration.  \\n \\nWindchillAdministrator')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGnjUBVbFrX2",
        "outputId": "33ee8f8d-d762-463f-f258-c962e6ea61e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
        "# from langchain.llms import HuggingFacePipeline\n",
        "# from langchain.chains import RetrievalQA\n",
        "# import accelerate\n",
        "\n",
        "# # tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "\n",
        "\n",
        "# # model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "#                                             #  device_map='auto',\n",
        "#                                             #  torch_dtype=torch.float16,\n",
        "#                                             #  use_auth_token=True,\n",
        "#                                             #  load_in_8bit=True,\n",
        "#                                             #   #load_in_4bit=True\n",
        "#                                             #  )\n",
        "# model_id = 'google/flan-t5-large'# go for a smaller model if you dont have the VRAM\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bit=True)\n",
        "# # model.to(device)\n",
        "\n",
        "# # pipe = pipeline(\"text-generation\",\n",
        "# #                 model=model,\n",
        "# #                 tokenizer= tokenizer,\n",
        "# #                 torch_dtype=torch.bfloat16,\n",
        "# #                 device_map=\"auto\",\n",
        "# #                 max_new_tokens = 1024,\n",
        "# #                 do_sample=True,\n",
        "# #                 top_k=10,\n",
        "# #                 num_return_sequences=1,\n",
        "# #                 eos_token_id=tokenizer.eos_token_id\n",
        "# #                 )\n",
        "\n",
        "# pipe = pipeline(\n",
        "#     \"text2text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     max_length=100\n",
        "# )\n",
        "# llm=HuggingFacePipeline(pipeline=pipe)\n",
        "# chain =  RetrievalQA.from_chain_type(llm=llm, retriever=vector_store.as_retriever())\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-40b-instruct\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"tiiuae/falcon-40b-instruct\")\n",
        "\n",
        "# model.to(device)\n",
        "\n",
        "# pipe = pipeline(\n",
        "#     \"text2text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer.to('cuda'),\n",
        "#     max_length=100\n",
        "# )\n",
        "\n",
        "# local_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "F5Smr2WOjIAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what does each access control policy rule do?\"\n",
        "res = chain({'query': query})\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d61JdXQ9PyZq",
        "outputId": "83046829-92e1-4b8d-dacd-7c5af1264d5f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'what does each access control policy rule do?', 'result': '\\n\\n1. \"Require users to provide their credentials before submitting an electronic signature at the submit button.\" - This access control policy rule ensures that users must provide their credentials before submitting an electronic signature.\\n\\n2. \"For OAuth delegated authorization, Windchill acts as a resource server to applications or mashups built on the ThingWorx platform.\" - This access control policy rule ensures that applications or mashups built on the ThingWorx platform can access Windch', 'source_documents': [Document(page_content='require users to provide their credentials before submitting an electronic sign ature. For more \\ninformation, seeeSignature Validation for SSO Configurations.  \\n \\nFor OAuth delegated authorization,Windchillacts as a resource serv er to applications or mashups \\nbuilt on theThingWorxplatform. If the user grants the application permission to access \\ntheirWindchilldata, then the application will present an access token toWindchillwhen requesting data owned by the user. PTC products affix scopes to access tokens to further protect and \\nmanage access to resources. InWindchill, scopes must be registered in \\nthesecurityContext.propertiesfile. For more information, seeEstablish a Central Authorization \\nServerandConfigure OAuth Delegated Authorization.  \\n \\nIn the OAuth delegated authorization scenario, PTC supports using PingFederate as a central \\nauthorization server (CAS) to manage the trust relationship between PTC products participating'), Document(page_content='The second change administrator (Change Administrator II) is responsible for creating th e \\nimplementation plan captured in the change notice. Change Administrator II is also responsible \\nfor recording the decision of the Change Implementation Board to proceed with the \\nimplementation plan.  \\n \\nThe third change administrator (Change Administrator III) acts as an auditor for all of the \\nmaterial related to a change, ensuring that all resulting documentation is clear, concise, and valid, \\nand that all process steps are properly executed.  \\n \\nChange Implementation Board (CIB)  \\n \\nA Change Implementation Board r eviews and either approves or denies the implementation plan \\nincluded in the change notice.  \\n \\nChange Notice  \\n \\nChange Notice  \\n \\nA change notice represents a work authorization to document and release new designs, to \\nenhance existing designs, or to correct problems  \\n \\nThe change notice can be created in reference to one or more change requests. It details the tasks'), Document(page_content='change in either the fast or full track branches of the change process. Change Administrator I \\nalso creates the change requests from unresolved problem reports.The second change \\nadministrator  (Change Administrator II) is responsible for creating the implementation plan \\ncaptured in the change notice. Change Administrator II is also responsible for recording the \\ndecision of the Change Implementation Board to proceed with the implementation plan. The third \\nchange administrator (Change Administrator III) acts as an auditor for all of the material related \\nto a change, ensuring that all resulting documentation is clear, concise, and valid, and that all \\nprocess steps are properly executed.Change Implem entation Board (CIB)A Change \\nImplementation Board reviews and either approves or denies the implementation plan included \\nin the change notice.Change NoticeA change notice represents a work authorization to document')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def handle_user_input(question):\n",
        "\n",
        "#     response = st.session_state.conversation({'question':question})\n",
        "#     st.session_state.chat_history = response['chat_history']\n",
        "\n",
        "#     for i, message in enumerate(st.session_state.chat_history):\n",
        "#         if i % 2 == 0:\n",
        "#             st.write(user_template.replace(\"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
        "#         else:\n",
        "#             st.write(bot_template.replace(\"{{MSG}}\", message.content), unsafe_allow_html=True)"
      ],
      "metadata": {
        "id": "YKQcF54RPMNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "#     load_dotenv()\n",
        "#     st.set_page_config(page_title='Chat with Your own PDFs', page_icon=':books:')\n",
        "\n",
        "#     st.write(css, unsafe_allow_html=True)\n",
        "\n",
        "#     if \"conversation\" not in st.session_state:\n",
        "#         st.session_state.conversation = None\n",
        "\n",
        "#     if \"chat_history\" not in st.session_state:\n",
        "#         st.session_state.chat_history = None\n",
        "\n",
        "#     st.header('Chat with Your own PDFs :books:')\n",
        "#     question = st.text_input(\"Ask anything to your PDF: \")\n",
        "\n",
        "#     if question:\n",
        "#         handle_user_input(question)\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         st.subheader(\"Upload your Documents Here: \")\n",
        "#         pdf_files = st.file_uploader(\"Choose your PDF Files and Press OK\", type=['pdf'], accept_multiple_files=True)\n",
        "\n",
        "#         if st.button(\"OK\"):\n",
        "#             with st.spinner(\"Processing your PDFs...\"):\n",
        "\n",
        "#                 # Get PDF Text\n",
        "#                 raw_text = get_pdf_text(pdf_files)\n",
        "\n",
        "#                 # Get Text Chunks\n",
        "#                 text_chunks = get_chunk_text(raw_text)\n",
        "\n",
        "#                 # Create Vector Store\n",
        "\n",
        "#                 vector_store = get_vector_store(text_chunks)\n",
        "#                 st.write(\"DONE\")\n",
        "\n",
        "#                 # Create conversation chain\n",
        "\n",
        "#                 st.session_state.conversation =  get_conversation_chain(vector_store)"
      ],
      "metadata": {
        "id": "Aah9WD9ZPg_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}